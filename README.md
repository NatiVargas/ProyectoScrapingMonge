# Web Scraping DinÃ¡mico y EstÃ¡tico con Almacenamiento en PostgreSQL ğŸš€



Un proyecto de **Rafael Antonio**, **Nathalia RamÃ­rez** y **Alonso Morales** que realiza *scraping* tanto en sitios web estÃ¡ticos como dinÃ¡micos, utilizando modelos de lenguaje (LLMs) para sugerir selectores CSS/XPath y almacenando toda la informaciÃ³n en PostgreSQL.

---

## ğŸŒŸ CaracterÃ­sticas Principales

- ğŸ•¸ï¸ **Scraping dual**: soporte para sitios estÃ¡ticos y dinÃ¡micos (JavaScript)
- ğŸ¤– **IntegraciÃ³n con LLMs**: generaciÃ³n automÃ¡tica de selectores CSS/XPath
- ğŸ—ƒï¸ **Almacenamiento robusto**: PostgreSQL para datos estructurados
- â° **Scheduling**: ejecuciÃ³n programada de scraping
- ğŸŒ **API REST**: acceso a los datos recolectados
- ğŸ–¥ï¸ **Interfaz web**: visualizaciÃ³n de resultados con frontend

---

## ğŸ—ï¸ Estructura del Proyecto

```plaintext
â”œâ”€â”€ scraper/                  
â”‚   â”œâ”€â”€ scraper_dynamic.py     # Scraping dinÃ¡mico (Selenium)
â”‚   â”œâ”€â”€ scraper_static.py      # Scraping estÃ¡tico (BeautifulSoup)
â”œâ”€â”€ data/                     
â”‚   â”œâ”€â”€ results.json           # Resultados de productos
â”‚   â”œâ”€â”€ files.json             # Archivos descargados
â”‚   â”œâ”€â”€ events.json            # Eventos del sistema
â”œâ”€â”€ db/                       
â”‚   â”œâ”€â”€ database.py            # ConexiÃ³n a PostgreSQL
â”‚   â”œâ”€â”€ logger.py              # Sistema de logging
â”œâ”€â”€ api/                      
â”‚   â””â”€â”€ json_api_server.py     # API REST para los datos
â”œâ”€â”€ docs/                     
â”‚   â””â”€â”€ GUÃA_INICIO.md         # GuÃ­a de inicio rÃ¡pido
â”œâ”€â”€ downloads/                 # Archivos descargados
â”œâ”€â”€ llm/                      
â”‚   â””â”€â”€ llm_selector.py        # Generador de selectores
â”œâ”€â”€ frontend/                 
â”‚   â”œâ”€â”€ index.html             # PÃ¡gina principal
â”‚   â”œâ”€â”€ styles.css             # Estilos CSS
â”‚   â”œâ”€â”€ main.js                # LÃ³gica principal
â”‚   â”œâ”€â”€ results.js             # VisualizaciÃ³n de resultados
â”‚   â”œâ”€â”€ files.js               # Manejo de archivos
â”‚   â”œâ”€â”€ calendar.js            # Calendario de eventos
â”œâ”€â”€ logs/                     
â”‚   â””â”€â”€ scraper.log            # Log de operaciones
â”œâ”€â”€ scheduler.py               # Programador de tareas
â”œâ”€â”€ main.py                   # Punto de entrada principal
â”œâ”€â”€ db_credentials.txt         # Credenciales de DB
â”œâ”€â”€ requirements.txt           # Dependencias
â”œâ”€â”€ serve_frontend.py          # Servidor web frontend
â”œâ”€â”€ .env                       # Variables de entorno
â””â”€â”€ README.md                  # Este archivo
```

---

## ğŸ› ï¸ ConfiguraciÃ³n Inicial

### ğŸ”½ Clonar el repositorio

```bash
git clone https://github.com/NatiVargas/ProyectoScrapingMonge.git
cd ProyectoScrapingMonge
```

### ğŸ’» Crear entorno virtual (opcional pero recomendado)

```bash
python -m venv venv
# Linux/macOS
source venv/bin/activate
# Windows
.\env\Scripts\ctivate
```

### ğŸ“¦ Instalar dependencias

```bash
pip install -r requirements.txt
```

### ğŸ—„ï¸ Configurar PostgreSQL

Crear un archivo llamado `db_credentials.txt` con el siguiente contenido:

```
tienda
postgres
contraseÃ±a_postgres
localhost
5432
```

### ğŸ”‘ Configurar LLM (opcional)

Crear un archivo `.env` con tu clave:

```
MISTRAL_API_KEY=TU_API_KEY
MISTRAL_MODEL=MODELO_DE_IA
```

---

## ğŸš€ CÃ³mo Usar

| Comando | DescripciÃ³n |
|--------|-------------|
| `python main.py` | Ejecuta el sistema completo |
| `python scraper/scraper_dynamic.py` | Ejecuta scraping dinÃ¡mico (Selenium) |
| `python scraper/scraper_static.py` | Ejecuta scraping estÃ¡tico (BeautifulSoup) |
| `python scheduler.py` | Inicia el programador de tareas |
| `python api/json_api_server.py` | Levanta el servidor API |
| `python serve_frontend.py` | Inicia el servidor web del frontend |

---

## ğŸ¤– Â¿Por quÃ© Selenium?

- Ideal para sitios con JavaScript pesado  
- Permite interacciÃ³n con paginaciÃ³n dinÃ¡mica  
- Soporte para scroll infinito  
- PrecisiÃ³n al capturar el DOM en tiempo real  

> Para sitios estÃ¡ticos usamos **BeautifulSoup** por su eficiencia y rapidez.

---

## ğŸ—ƒï¸ Arquitectura del Sistema

```mermaid
graph TD
    A[Scraper DinÃ¡mico] -->|Datos| B[(PostgreSQL)]
    C[Scraper EstÃ¡tico] -->|Datos| B
    D[LLM Selector] -->|CSS/XPath| A
    D -->|CSS/XPath| C
    B -->|API| E[Frontend Web]
    B -->|API| F[AnÃ¡lisis Futuro]
```

---

## ğŸ‘¥ Contribuidores

- **Rafael Antonio** â€” Scraping dinÃ¡mico  
- **Nathalia RamÃ­rez** â€” Base de datos y API  
- **Alonso Morales** â€” Frontend e integraciÃ³n con LLM

---

## ğŸ“Œ Nota Final

Este proyecto forma parte del curso de **ComputaciÃ³n en la Nube**.  
Para cualquier consulta, no dudes en contactar al equipo.  
Â¡Gracias por visitar el repositorio! ğŸ™Œ
